{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5921336a-8e52-4c60-ae66-d49c7c0ee3a6",
   "metadata": {},
   "source": [
    "## Table Of Contents:\n",
    "* [Text Generation Models ](#text-gen)\n",
    "* [Text Summarization Models](#text-summ)\n",
    "* [How to write SQL queries with OpenAI](#write-sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4448c633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /Users/umarala/anaconda3/envs/env312/lib/python3.12/site-packages (1.13.3)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/umarala/anaconda3/envs/env312/lib/python3.12/site-packages (from openai) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/umarala/anaconda3/envs/env312/lib/python3.12/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/umarala/anaconda3/envs/env312/lib/python3.12/site-packages (from openai) (0.26.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/umarala/anaconda3/envs/env312/lib/python3.12/site-packages (from openai) (2.6.3)\n",
      "Requirement already satisfied: sniffio in /Users/umarala/anaconda3/envs/env312/lib/python3.12/site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /Users/umarala/anaconda3/envs/env312/lib/python3.12/site-packages (from openai) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /Users/umarala/anaconda3/envs/env312/lib/python3.12/site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/umarala/anaconda3/envs/env312/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
      "Requirement already satisfied: certifi in /Users/umarala/anaconda3/envs/env312/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/umarala/anaconda3/envs/env312/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (1.0.3)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/umarala/anaconda3/envs/env312/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/umarala/anaconda3/envs/env312/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in /Users/umarala/anaconda3/envs/env312/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (2.16.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7defdbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ab08a8e-256b-454c-8004-d9a3333e97f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8af9b814-f2ed-4ffb-8aaf-d501f3eefb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52ed9c23-e298-4506-9fd1-7d5564ad032b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sk\n"
     ]
    }
   ],
   "source": [
    "print(openai.api_key[0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396a2d67-5e47-4ce8-beeb-9bceb33abffa",
   "metadata": {},
   "source": [
    "### Pretty Printing Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e81b7b1-c259-4fb9-a432-5f2b8c162215",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def show_json(obj):\n",
    "    display(json.loads(obj.model_dump_json()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76538df5-f5ed-4313-9d61-d8b2649170a2",
   "metadata": {},
   "source": [
    "### Text Generation Models <a class=\"text-gen\" id=\"text-gen\"></a>\n",
    "\n",
    "OpenAI's text generation models (often called generative pre-trained transformers or large language models) have been trained to understand natural language, code, and images. \n",
    "\n",
    "The models provide text outputs in response to their inputs. The inputs to these models are also referred to as \"prompts\". \n",
    "\n",
    "Designing a prompt is essentially how you “program” a large language model model, usually by providing instructions or some examples of how to successfully complete a task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed1a6804-ea56-4456-8bbc-a7196a59ab85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Who won the world series in 2020?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"The Los Angeles Dodgers won the World Series in 2020.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Where was it played?\"}\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27679fc-622e-4d8e-a927-9134959d972f",
   "metadata": {},
   "source": [
    "**The main input is the messages parameter-**\n",
    "\n",
    "Messages must be an array of message objects, where each object has a role (either \"system\", \"user\", or \"assistant\") and content (the content of the message). Conversations can be as short as 1 message or fill many pages.\n",
    "\n",
    "Typically, a conversation is formatted with a system message first, followed by alternating user and assistant messages.\n",
    "\n",
    "- The system message helps set the behavior of the assistant. In the example above, the assistant was instructed with \"You are a helpful assistant.\"\n",
    "\n",
    "- The user messages help instruct the assistant. They can be generated by the end users of an application, or set by a developer as an instruction.\n",
    "\n",
    "- The assistant messages help store prior responses. They can also be written by a developer to help give examples of desired behavior.\n",
    "\n",
    "Including the conversation history helps when user instructions refer to prior messages. In the example above, the user’s final question of \"Where was it played?\" only makes sense in the context of the prior messages about the World Series of 2020. Because the models have no memory of past requests, all relevant information must be supplied via the conversation. If a conversation cannot fit within the model’s token limit, it will need to be shortened in some way.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "542549aa-76e5-4451-b4f8-d2575460a490",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'chatcmpl-8zFMxWSRQfRp2delPvXl3IZVWXlCu',\n",
       " 'choices': [{'finish_reason': 'stop',\n",
       "   'index': 0,\n",
       "   'logprobs': None,\n",
       "   'message': {'content': 'The 2020 World Series was played at a neutral site, Globe Life Field in Arlington, Texas, due to the COVID-19 pandemic.',\n",
       "    'role': 'assistant',\n",
       "    'function_call': None,\n",
       "    'tool_calls': None}}],\n",
       " 'created': 1709607779,\n",
       " 'model': 'gpt-3.5-turbo-0125',\n",
       " 'object': 'chat.completion',\n",
       " 'system_fingerprint': 'fp_2b778c6b35',\n",
       " 'usage': {'completion_tokens': 29, 'prompt_tokens': 53, 'total_tokens': 82}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_json(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6bcd0b3d-b99d-4c7e-af2c-9ff4b587d57e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The 2020 World Series was played at a neutral site, Globe Life Field in Arlington, Texas, due to the COVID-19 pandemic.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69825983-6703-4d66-8df6-ff2563e54b43",
   "metadata": {},
   "source": [
    "In Python, the assistant’s reply can be extracted with response.choices[0].message.content\n",
    "\n",
    "Every response will include a finish_reason. The possible values for finish_reason are:\n",
    "\n",
    "- stop: API returned complete model output\n",
    "- length: Incomplete model output due to max_tokens parameter or token limit\n",
    "- content_filter: Omitted content due to a flag from our content filters\n",
    "- null: API response still in progress or incomplete"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b094d2d7-30df-4e48-9cf9-5fccebcf9c70",
   "metadata": {},
   "source": [
    "### Text Summarization Models <a class=\"text-summ\" id=\"text-summ\"></a>\n",
    "\n",
    "We want to generate a short summary of a product review from an ecommerce site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a6993ca9-13a9-4957-b500-b2019a76f497",
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_review = f\"\"\"\n",
    "Got this panda plush toy for my daughter's birthday, \\\\\n",
    "who loves it and takes it everywhere. It's soft and \\\\ \n",
    "super cute, and its face has a friendly look. It's \\\\\n",
    "a bit small for what I paid though. I think there \\\\ \n",
    "might be other options that are bigger for the \\\\ \n",
    "same price. It arrived a day earlier than expected, \\\\\n",
    "so I got to play with it myself before I gave it \\\\ \n",
    "to her.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "060e9364-1b53-44f6-8032-bf11fa43567d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "def get_completion(prompt, model=\"gpt-3.5-turbo\"): # Andrew mentioned that the prompt/ completion paradigm is preferable for this class\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0, # this is the degree of randomness of the model's output\n",
    "    )\n",
    "    return response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bd4b9de2-548f-4f0d-81a9-17d2817de9c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```\n",
      "Cute panda plush toy loved by daughter, soft and friendly-looking. Smaller than expected for the price, but arrived early.\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Your task is to generate a short summary of a product \\\n",
    "review from an ecommerce site. \n",
    "\n",
    "Summarize the review below, delimited by triple \n",
    "backticks, in at most 30 words. \n",
    "\n",
    "Review: ```{prod_review}```\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fcffc4c-5703-4e40-b362-f5bc64e33000",
   "metadata": {},
   "source": [
    "### How to write SQL queries with OpenAI <a class=\"write-sql\" id=\"write-sql\"></a>\n",
    "\n",
    "We want a SQL query to be generated which computes the average total order value for all orders on 2023-04-01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9924a3-c1ea-4777-85e7-0accc1151338",
   "metadata": {},
   "source": [
    "Given the following SQL tables, your job is to write queries given a user’s request.\n",
    "    \n",
    "    CREATE TABLE Orders (\n",
    "      OrderID int,\n",
    "      CustomerID int,\n",
    "      OrderDate datetime,\n",
    "      OrderTime varchar(8),\n",
    "      PRIMARY KEY (OrderID)\n",
    "    );\n",
    "    \n",
    "    CREATE TABLE OrderDetails (\n",
    "      OrderDetailID int,\n",
    "      OrderID int,\n",
    "      ProductID int,\n",
    "      Quantity int,\n",
    "      PRIMARY KEY (OrderDetailID)\n",
    "    );\n",
    "    \n",
    "    CREATE TABLE Products (\n",
    "      ProductID int,\n",
    "      ProductName varchar(50),\n",
    "      Category varchar(50),\n",
    "      UnitPrice decimal(10, 2),\n",
    "      Stock int,\n",
    "      PRIMARY KEY (ProductID)\n",
    "    );\n",
    "    \n",
    "    CREATE TABLE Customers (\n",
    "      CustomerID int,\n",
    "      FirstName varchar(50),\n",
    "      LastName varchar(50),\n",
    "      Email varchar(100),\n",
    "      Phone varchar(20),\n",
    "      PRIMARY KEY (CustomerID)\n",
    "    );\n",
    "\n",
    "USER\n",
    "\n",
    "Write a SQL query which computes the average total order value for all orders on 2023-04-01.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "35653007-b708-4a62-b3b7-89edb2bcff37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": \"Given the following SQL tables, your job is to write queries given a user’s request.\\n    \\n    CREATE TABLE Orders (\\n      OrderID int,\\n      CustomerID int,\\n      OrderDate datetime,\\n      OrderTime varchar(8),\\n      PRIMARY KEY (OrderID)\\n    );\\n    \\n    CREATE TABLE OrderDetails (\\n      OrderDetailID int,\\n      OrderID int,\\n      ProductID int,\\n      Quantity int,\\n      PRIMARY KEY (OrderDetailID)\\n    );\\n    \\n    CREATE TABLE Products (\\n      ProductID int,\\n      ProductName varchar(50),\\n      Category varchar(50),\\n      UnitPrice decimal(10, 2),\\n      Stock int,\\n      PRIMARY KEY (ProductID)\\n    );\\n    \\n    CREATE TABLE Customers (\\n      CustomerID int,\\n      FirstName varchar(50),\\n      LastName varchar(50),\\n      Email varchar(100),\\n      Phone varchar(20),\\n      PRIMARY KEY (CustomerID)\\n    );\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"Write a SQL query which computes the average total order value for all orders on 2023-04-01.\"\n",
    "    }\n",
    "  ],\n",
    "  temperature=0.7,\n",
    "  max_tokens=1000,\n",
    "  top_p=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30a7b85-7081-490b-b3fb-be35cd5ae5c0",
   "metadata": {},
   "source": [
    "**Adjust your settings-**\n",
    "\n",
    "Prompt design is not the only tool you have at your disposal. You can also control completions by adjusting your settings. \n",
    "\n",
    "**-temperature**\n",
    "\n",
    "One of the most important settings is called **temperature**.\n",
    "\n",
    "You may have noticed that if you submitted the same prompt multiple times in the examples above, the model would always return identical or very similar completions. This is because your temperature was set to 0.\n",
    "\n",
    "Try re-submitting the same prompt a few times with temperature set to 1.\n",
    "\n",
    "When temperature is above 0, submitting the same prompt results in different completions each time.\n",
    "\n",
    "Remember that the model predicts which text is most likely to follow the text preceding it. \n",
    "\n",
    "**temperature is a value between 0 and 1** that essentially lets you control how confident the model should be when making these predictions. \n",
    "\n",
    "Lowering temperature means it will take fewer risks, and completions will be more **accurate and deterministic**. \n",
    "\n",
    "Higher temperature may be useful for tasks where variety or **creativity are desired**, or if you'd like to generate a few variations for your end users or human experts to choose from.\n",
    "\n",
    "**-max_tokens**\n",
    "\n",
    "specifies the length of the generated tokens\n",
    "\n",
    "**-top_p(nucleus)**\n",
    "\n",
    "sampling limits token generation to the cumulative probability of p.\n",
    "The cumulative probability cutoff for token selection. Lower values mean sampling from a smaller, more top-weighted nucleus.\n",
    "\n",
    "**-top_k**\n",
    "\n",
    "sampling limits token generation to the top k most likely tokens at each step\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "584a5f29-3cfe-4be7-811e-f3bfeaf07b77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'chatcmpl-90KE9IbTxb8Vdbj7SmsuHRg5c74Pp',\n",
       " 'choices': [{'finish_reason': 'stop',\n",
       "   'index': 0,\n",
       "   'logprobs': None,\n",
       "   'message': {'content': \"```sql\\nSELECT AVG(TotalOrderValue) AS AverageTotalOrderValue\\nFROM (\\n    SELECT O.OrderID, SUM(OD.Quantity * P.UnitPrice) AS TotalOrderValue\\n    FROM Orders O\\n    JOIN OrderDetails OD ON O.OrderID = OD.OrderID\\n    JOIN Products P ON OD.ProductID = P.ProductID\\n    WHERE O.OrderDate = '2023-04-01'\\n    GROUP BY O.OrderID\\n) AS OrderTotals;\\n```\",\n",
       "    'role': 'assistant',\n",
       "    'function_call': None,\n",
       "    'tool_calls': None}}],\n",
       " 'created': 1709864781,\n",
       " 'model': 'gpt-3.5-turbo-0125',\n",
       " 'object': 'chat.completion',\n",
       " 'system_fingerprint': 'fp_2b778c6b35',\n",
       " 'usage': {'completion_tokens': 98, 'prompt_tokens': 217, 'total_tokens': 315}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_json(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "042c42b3-9075-473f-9745-b53c0661a953",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"```sql\\nSELECT AVG(TotalOrderValue) AS AverageTotalOrderValue\\nFROM (\\n    SELECT O.OrderID, SUM(OD.Quantity * P.UnitPrice) AS TotalOrderValue\\n    FROM Orders O\\n    JOIN OrderDetails OD ON O.OrderID = OD.OrderID\\n    JOIN Products P ON OD.ProductID = P.ProductID\\n    WHERE O.OrderDate = '2023-04-01'\\n    GROUP BY O.OrderID\\n) AS OrderTotals;\\n```\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message.content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
